<!doctype html><html lang=en><head><meta http-equiv=Content-Type content="text/html" charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1"><title>Using AWS Rekognition facial recognition with deeplens</title><link rel=stylesheet href="/css/style.min.25809aa7b6b40c786224962f821dc77b5f6156d67c0ee11170c034476a1a4e4a.css" integrity="sha256-JYCap7a0DHhiJJYvgh3He19hVtZ8DuERcMA0R2oaTko="><script type=text/javascript src=/js/dark_light_mode.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6DH827VXED"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6DH827VXED")}</script></head><body class="dark:bg-zinc-900 dark:text-white"><div class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex h-screen flex-col justify-between"><header><div class="flex items-center pb-10 pt-7"><div class="mx-auto sm:mr-8"><a class="py-2 px-4 rounded-full" href=/>Home</a> <a class="bg-sky-200 dark:bg-sky-700 py-2 px-4 rounded-full" href=/blog>Blog</a> <a class="py-2 px-4 rounded-full" href=/projects>Projects</a> <a class="py-2 px-4 rounded-full" href=/about>About</a></div></div></header><div class="fixed right-0 bottom-0 mr-6 mb-6"><div><button onclick=toggleLightDarkMode()><div class="h-1/2 border-2 rounded-full p-3 bg-zinc-900 dark:bg-white"><span class="hidden w-5 dark:block text-zinc-900"><span><svg viewBox="0 0 512 512"><path fill="currentColor" d="M505.2 324.8l-47.73-68.78 47.75-68.81c7.359-10.62 8.797-24.12 3.844-36.06-4.969-11.94-15.52-20.44-28.22-22.72l-82.39-14.88-14.89-82.41c-2.281-12.72-10.76-23.25-22.69-28.22-11.97-4.936-25.42-3.498-36.12 3.844L256 54.49 187.2 6.709c-10.7-7.3106-24.1-8.748-36.1-3.813-11.92 4.971-20.4 15.5-22.7 28.19l-14.89 82.44L31.15 128.4C18.42 130.7 7.854 139.2 2.9 151.2c-4.951 11.9-3.4996 25.4 3.875 36l47.73 68.78-47.75 68.81c-7.359 10.62-8.795 24.12-3.844 36.06 4.969 11.94 15.52 20.44 28.22 22.72l82.39 14.88 14.89 82.41c2.297 12.72 10.78 23.25 22.7 28.22 11.95 4.906 25.44 3.531 36.09-3.844L256 457.5l68.83 47.78C331.3 509.7 338.8 512 346.3 512c4.906.0 9.859-.9687 14.56-2.906 11.92-4.969 20.4-15.5 22.7-28.19l14.89-82.44 82.37-14.88c12.73-2.281 23.3-10.78 28.25-22.75C514.1 348.9 512.6 335.4 505.2 324.8zm-48.4 14.4-99.61 18-18 99.63L256 399.1l-83.2 57.7-18-99.63-99.61-18L112.9 255.1 55.23 172.8l99.61-18 18-99.63L256 112.9l83.15-57.75 18.02 99.66 99.61 18L399.1 255.1l57.7 84.1zM256 143.1c-61.85.0-111.1 50.14-111.1 111.1.0 61.85 50.15 111.1 111.1 111.1s111.1-50.14 111.1-111.1c0-60.1-49.3-111.1-111.1-111.1zm0 176c-35.28.0-63.99-28.71-63.99-63.99S220.7 192 256 192s63.99 28.71 63.99 63.1-28.69 64-63.99 64z"/></svg>
</span></span><span class="dark:hidden w-5 block text-white"><span><svg viewBox="0 0 512 512"><path fill="currentColor" d="M421.6 379.9c-.6641.0-1.35.0625-2.049.1953-11.24 2.143-22.37 3.17-33.32 3.17-94.81.0-174.1-77.14-174.1-175.5.0-63.19 33.79-121.3 88.73-152.6 8.467-4.812 6.339-17.66-3.279-19.44-11.2-2.078-29.53-3.746-40.9-3.746C132.3 31.1 32 132.2 32 256c0 123.6 100.1 224 223.8 224 69.04.0 132.1-31.45 173.8-82.93C435.3 389.1 429.1 379.9 421.6 379.9zM255.8 432C158.9 432 80 353 80 256c0-76.32 48.77-141.4 116.7-165.8-21.5 34.8-33.5 75.4-33.5 117.6.0 99.44 65.13 183.9 154.9 212.8-19.6 7.5-40.7 11.4-62.3 11.4z"/></svg></span></span></div></button></div></div><div class="text-center py-7"><div class="flex flex-col space-y-3"><div><dt class=sr-only>Published on</dt><dd class="text-base font-medium leading-6 text-zinc-500"><time datetime="2020-03-11 00:00:00 +0000 UTC">Mar 11, 2020</time></dd></div><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-zinc-900 dark:text-zinc-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">Using AWS Rekognition facial recognition with deeplens</h1><p class="text-base leading-6 text-zinc-500">5 min read</p></div><article class="prose dark:prose-invert prose-h1:font-bold max-w-none text-left mx-auto pt-7"><p>Deeplens is a cool product from AWS, so called a &ldquo;deep learning enabled video camera&rdquo; that let you to deploy machine learning models easily to it, and run inference on the live feed. Kind of a like a Raspberry Pi with webcam, but much powerful and easier to setup(that&rsquo;s if you are familiar with AWS).</p><p>Face recognition, is a complex problem that takes several steps as mentioned in my previous post on <a href=https://jabeztho.com/blog/using-aws-rekognition-for-face-recognition/>&ldquo;Using AWS Rekognition For Face Recognition&rdquo;</a>.</p><p>Although we can definitely train on a specific individual face using object detection model methodologies, it is more suited for smaller datasets and doesn&rsquo;t scale well in terms of more faces being added into the model.</p><p>As such we opt to instead do the face detection on the Deeplens ecosystem, then pass the found face to a dedicated face recognition system that can also be run locally on the deeplens as well or to the cloud. In this guide we pass our faces to AWS rekognition which I had well covered on how to setup face recognition on over <a href=https://jabeztho.com/blog/using-aws-rekognition-for-face-recognition/>here</a>.</p><p>For this project we didn&rsquo;t have to store the face image taken in persistent storage as we store the Image in a binary stream before sending to AWS rekognition in bytes.</p><h1 id=step-1---setup-your-deeplens>Step 1 - Setup your Deeplens</h1><ol><li><p>Register your Deeplens to your AWS account using the <a href=https://docs.aws.amazon.com/deeplens/latest/dg/deeplens-getting-started-register.html>AWS Developer guide</a>, enable the SSH option when setting up internet connection.</p></li><li><p>Get your Deeplens ip address from your Deeplens device&rsquo;s page, and use that ip to SSH in using a SSH client, with the username being &lsquo;aws_cam&rsquo; and password whatever you had keyed in during the setup</p><p><img src=images/ipaddr-dl.png alt=ip-address></p></li><li><p>install the necessary dependencies for Image processing of JPEG (libjpeg) in the SSH session</p><pre tabindex=0><code>sudo apt-get install libjpeg-dev
</code></pre></li><li><p>Go to IAM management on AWS web console, Services > IAM (under Security, Identity, & Compliance)</p><p><img src=images/console-page-rekog-tut.png alt=iam></p></li><li><p>Click roles, and search for <strong>AWSDeepLensGreengrassGroupRole</strong> and select it</p><p><img src=images/ggrole-dl.png alt=greengrass-role></p></li><li><p>Select <strong>Attach policies</strong> and search for <strong>AmazonRekognitionReadOnlyAccess</strong> and select it, at the bottom select <strong>Attach policy</strong> to finish</p><p><img src=images/attach-pol-dl.png alt=attach-policy></p></li></ol><h1 id=step-2---create-deeplens-project>Step 2 - create Deeplens project</h1><ol><li><p>Go to Deeplens page on AWS web console, Services > Deeplens (under Machine learning).</p><p><img src=images/deeplens-dl.png alt=select-deeplens></p></li><li><p>Select <strong>Projects</strong> from the side menu, and click <strong>Create new project</strong>.</p><p><img src=images/create-prog-sel-dl.png alt=select-deeplens></p></li><li><p>Choose <strong>Use a project template</strong> select <strong>Face detection</strong> and click <strong>Next</strong> to proceed.</p><p><img src=images/proj-temp-sel-dl.png alt=select-template></p></li><li><p>On <strong>Specify project details</strong> enter your desired name and details before clicking <strong>Create</strong></p><p><img src=images/finish-create-dl.png alt=review></p></li><li><p>Clone this git reposistory from <a href=https://github.com/Jasperabez/deeplens-rekognition-lambda>here</a></p><pre tabindex=0><code>git clone https://github.com/Jasperabez/deeplens-rekognition-lambda.git
</code></pre></li><li><p>Zip it using into a .zip file using any tool(7zip, Winrar)</p></li><li><p>Update your lambda with it using AWS CLI, if you don&rsquo;t have AWS CLI follow this <a href=https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html>guide</a></p><pre tabindex=0><code>aws lambda update-function-code --function-name deeplens-face-detection --zip-file fileb://deeplens-rekognition-lambda.zip
</code></pre><p>make sure the zip-file path is correct</p></li></ol><h1 id=step-3---deploy-your-project-to-aws-deeplens>Step 3 - deploy your project to AWS Deeplens</h1><ol><li><p>Back to the deeplens project page, select your created project</p><p><img src=images/sel-fin-proj-dl.png alt=select-project></p></li><li><p>Select <strong>deploy to device</strong>, choose the device you&rsquo;ve created in Step 1 and click <strong>review</strong></p><p><img src=images/deploy-butt.png alt=select-project></p><p><img src=images/target-dev-dl.png alt=target-device-selection></p></li><li><p>After you click <strong>Deploy</strong> you should be redirected to your device page, and see the model deployment progress.</p></li><li><p>Once you see <strong>Deployment of project Face-detection, version 1 succeeded.</strong>, view the video stream by following <a href=https://docs.aws.amazon.com/deeplens/latest/dg/deeplens-viewing-output.html>this guide</a>.</p></li><li><p>To view MQTT messages follow these guidelines, that is listed on your Deeplens device&rsquo;s page</p><p><img src=images/mqtt-guidelines-dl.png alt=target-device-selection></p><p>message format is either &lsquo;{ }&rsquo; or &lsquo;{name:&mldr;, confidence:&mldr;, face:&mldr;}&rsquo;</p><p>face represents how confidence the deeplens model think that&rsquo;s a face</p></li></ol><h1 id=interesting-findings>Interesting findings</h1><h2 id=1-pip-install-differences-in-amazon-linux-vs-manjaropython>1. Pip install differences in Amazon Linux vs Manjaro(python)</h2><p>Following this <a href=https://docs.aws.amazon.com/lambda/latest/dg/python-package.html>AWS Development Guide</a> on &lsquo;AWS Lambda Deployment Package in Python&rsquo; I did a:</p><pre tabindex=0><code>pip install --target . Pillow
</code></pre><p>on my folder that is holding the relevant lambda code, because I had to use the Pillow library to save the numpy array into an Image before sending it off to Rekognition.</p><p>However I ran into this Error when I deployed my project on the Deeplens</p><pre tabindex=0><code>ImportError: cannot import name _imaging
</code></pre><p>After some googling there&rsquo;s a someone on stackoverflow that had the same issue as mine: <a href=https://stackoverflow.com/questions/46093874/lambda-uploader-unable-to-import-module-createthumbnail-cannot-import-name>Lambda-Uploader: Unable to import module &lsquo;CreateThumbnail&rsquo;: cannot import name _imaging</a>.</p><p>Apparently the solution requires me to whip up a EC2 Amazon Linux instance, ssh into it and do the pip install in there instead of doing it in a standard linux distribution due to some environment differences, which is kind of a pain as I only needed to grab that one library.</p><p>Looking down however there&rsquo;s this guy who refer the Original Poster to get his libraries from a Github reposistory called: <a href=https://github.com/Miserlou/lambda-packages>Lambda packages</a> by <a href=https://github.com/Miserlou>Rich Jones</a> who had precompiled some commonly used python libraries in an Amazon Linux instance. So I grab the Pillow library from there instead.</p><p>It did solve the ImportError but it bought up a new error:</p><pre tabindex=0><code>Failed to import handler function &#34;greengrassHelloWorld.function_handler&#34; due to exception: libjpeg.so.62: cannot open shared object file: No such file or directory
</code></pre><h2 id=2-greengrass-lambda-seems-to-run-locally-or-at-least-compiled-to-a-local-script-of-some-form>2. Greengrass Lambda seems to run locally or at least compiled to a local script of some form</h2><p>From my prior experiences with AWS lambda, lambda code is run in the cloud on some random AWS EC2 instance. However while reading some documentation on Greegrass and Deeplens and at least in this Image from AWS:</p><p><img src=images/framework-dl.jpg alt=frame-work></p><p>along with the fact that same python libraries imported in the AWS lambda function could also be import locally on the Deeplens while SSH into.</p><pre tabindex=0><code>import aws_cam
</code></pre><p>I had a suspicion that the lambda function is ran locally in some form or another.</p><p>Back to my previous error:</p><pre tabindex=0><code>Failed to import handler function &#34;greengrassHelloWorld.function_handler&#34; due to exception: libjpeg.so.62: cannot open shared object file: No such file or directory
</code></pre><p>I did some googling but the results were not promising, but with my limited linux experience I hypothesize that it should be a missing dependencies on the linux distribution and along with the idea that the lambda might be run locally, I SSH into the deeplens as the user aws_cam user and ran:</p><pre tabindex=0><code>sudo apt install libjpeg-dev
</code></pre><p>and surprisingly it worked!! So this seems to prove the notion of lambda being run in some form or another as I managed to fixed the error by installing the dependency <strong>locally</strong> on the deeplens.</p><p>But I did also note that simply doing:</p><pre tabindex=0><code>pip install Pillow
</code></pre><p>locally on the deeplens doesn&rsquo;t seems to work, as I would have a module not found error. I&rsquo;ll have to use the method I mentioned at the &rsquo; Pip install differences in Amazon Linux vs Manjaro(python)&rsquo; section. Just something to think about.</p><p>In the end however I did also copied the libjpeg.so.62 file from the</p><pre tabindex=0><code>/usr/lib64
</code></pre><p>folder from my Manjaro setup and put into the root directory of the lambda function for good measure. However, didn&rsquo;t try out whether the lambda will work with this workaround instead of installing libjpeg locally on the deeplens.</p></article></div><footer><div class="mt-4 flex flex-col items-center pt-8 pb-6 lg:pt-8 lg:pb-6"><div class="mt-2 flex space-x-4"><a href=https://github.com/Jasperabez><span class="w-6 h-6 block"><span><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a href=https://www.linkedin.com/in/jabez-tho-6b49a0184><span class="w-6 h-6 block"><span><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a><a href=mailto:jabeztho@gmail.com><span class="w-6 h-6 block"><span><svg viewBox="0 0 512 512"><path fill="currentColor" d="M0 128C0 92.65 28.65 64 64 64H448c35.3.0 64 28.65 64 64V384c0 35.3-28.7 64-64 64H64c-35.35.0-64-28.7-64-64V128zm48 0v22.1L220.5 291.7c20.6 17 50.4 17 71 0L464 150.1v-23C464 119.2 456.8 111.1 448 111.1H64C55.16 111.1 48 119.2 48 127.1V128zm0 84.2V384C48 392.8 55.16 4e2 64 4e2H448C456.8 4e2 464 392.8 464 384V212.2L322 328.8c-38.4 31.5-93.6 31.5-132.9.0L48 212.2z"/></svg></span></span></a></div><span class="mt-4 font-light text-xs">© 2025 Jabez Tho</span></div></footer></div></div></body></html>